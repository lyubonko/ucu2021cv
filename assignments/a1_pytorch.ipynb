{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of a1_pytorch.ipynb","provenance":[{"file_id":"https://github.com/lyubonko/ucu2020cv/blob/master/assignments/a1_pytorch.ipynb","timestamp":1637183635696}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"637S0mjilkvv"},"source":["![pytorch](https://upload.wikimedia.org/wikipedia/commons/9/96/Pytorch_logo.png)"]},{"cell_type":"markdown","metadata":{"id":"-aEaNoZtlkvw"},"source":["### Useful Links:\n","\n","* pytorch official documentation\n","http://pytorch.org/docs/master/index.html\n","\n","* pytorch discussion\n","https://discuss.pytorch.org/\n","\n","* pytorch official tutorials\n","https://pytorch.org/tutorials/\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yjTBYu_blkvx"},"source":["## Preliminaries"]},{"cell_type":"code","metadata":{"id":"agpPjG0Mlkv2"},"source":["import numpy as np\n","import torch\n","import torchvision"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKHlgFk8IUdT"},"source":["# print versions\n","from platform import python_version\n","print(f\"python version: {python_version()}\")\n","print(f\"torch version: {torch.__version__}\")\n","print(f\"torchvision version: {torchvision.__version__}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yCxjj52jlkv5"},"source":["# set random seeds\n","torch.manual_seed(42)\n","np.random.seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZRnBcOudlkv8"},"source":["##  Tensors"]},{"cell_type":"markdown","metadata":{"id":"34t2aUsZlkv9"},"source":["One of the main data types in PyTorch is 'tensor'.\n","We will start with the concept of tensor and how it is used in PyTorch.\n","\n","![](https://raw.githubusercontent.com/lyubonko/ucu2021cv/master/assignments/fig/tensors.jpg)"]},{"cell_type":"markdown","metadata":{"id":"41I0TEmRlkv-"},"source":["### Tensor Initialization"]},{"cell_type":"code","metadata":{"id":"w63UyQFvlkv_"},"source":["# initialization of 1d tensor of size 64 of type float32 (default)\n","# (this tensor is initialized with default values close to zero)\n","\n","tensor_inits = [\n","                \n","  # initialization of 1d tensor of size 64 of type float32 (default)\n","  # (this tensor is initialized with default values close to zero)                \n","  torch.empty(64),\n","\n","  # initialize with array [0,1,...,63]\n","  torch.arange(0,64),\n","\n","  # tensor with all zeros\n","  torch.zeros(8, 8, dtype=torch.long),\n","\n","  # tensor with all ones\n","  torch.ones(8, 8, dtype=torch.float32),\n","\n","  # random tensor with values in range [0,1)\n","  torch.rand((3,3,3)),\n","\n","  # tensor with random int values\n","  torch.randint(10, (2,2))\n","]\n","\n","for v in tensor_inits:\n","  print(f\" * the first 2 elements are: \\n \\t{v[:2]} \")\n","  print(f\"   the type of this tensor is {v.dtype}\")\n","  print(f\"   the size is {v.size()} \\n\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_FCufMClkwE"},"source":["# initialize with array all ones\n","x = torch.ones(8, 8, dtype=torch.float)\n","\n","print(f\" * the size of the 'x' is: \\n {x.size()} \\n\")\n","print(f\" * the size of the 'x' can also be obtained by familar from numpy 'shape' command: \\n {x.shape}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7SpXbIflk-06"},"source":["#### <font color=\"red\">**[PROBLEM I]:** </font>"]},{"cell_type":"markdown","metadata":{"id":"yIxLwDqJlkwI"},"source":["-----\n","\n"," <font color=\"red\"> Initialize X </font>     \n"," <font color=\"red\"> 3d Tensor of size (4,4,4) </font>   \n"," <font color=\"red\"> of type int32 with all elements equal to 10 </font>   \n","\n","-----"]},{"cell_type":"code","metadata":{"id":"IDKTCF-FlkwJ"},"source":["# YOUR CODE HERE (replace 'None')\n","X = None "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9PBunfBLlkwL"},"source":["print(X.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V6lo7g0vlkwP"},"source":["### Reshaping, broadcasting"]},{"cell_type":"markdown","metadata":{"id":"tvQ9VswXlkwQ"},"source":["Tensor reshaping is done with command 'view':"]},{"cell_type":"code","metadata":{"id":"9EZqQ4bolkwR"},"source":["a = torch.tensor([[1,2], [3,4]])\n","a_reshaped = a.view(4) # reshape into one-dimensional tensor of size 4\n","\n","print(a)\n","print(a_reshaped)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"byYJI7uNk-08"},"source":["#### <font color=\"red\">**[PROBLEM II]:** </font>"]},{"cell_type":"markdown","metadata":{"id":"PbfinsFPlkwU"},"source":["-----\n","\n"," <font color=\"red\"> Use command 'view' to reshape **v** and **X** (obtained in PROBLEM I) into 2d <ins>*square*</ins> tensors  **v_** and **X_**. </font>  \n","\n","  <font color=\"red\">Convet all tensors to type **int16** </font>\n","\n"," <font color=\"red\"> Perform addition of these reshaped tensors, namely calculate **sum_tensor** = **v_** + **X_** + **x** </font>  \n","\n"," <font color=\"red\"> Finally display the result. </font>\n","\n","-----"]},{"cell_type":"code","metadata":{"id":"vAqMDyT7lkwV"},"source":["v = torch.ones(64)\n","\n","# YOUR CODE HERE (replace 'None')\n","v_ = None  \n","X_ = None \n","sum_tensors = None \n"," \n","print(sum_tensors)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7MIoop_flkwY"},"source":["### Operations on Tensors"]},{"cell_type":"markdown","metadata":{"id":"ob2KRkFRRScX"},"source":["relevant tutorial\n","https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#operations"]},{"cell_type":"markdown","metadata":{"id":"lo6Y9pB8lkwZ"},"source":["There are multiple syntaxes for different operations. As starters let us look for 'addition' operation."]},{"cell_type":"code","metadata":{"id":"zeUMQde7Rnyo"},"source":["x = torch.randint(10, (4, 4))\n","y = torch.ones(4,4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jx9pgVR-RxfU"},"source":["print(torch.add(x, y))\n","print(x + y)\n","result = torch.empty_like(y)\n","torch.add(x, y, out=result)\n","print(result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mk9fcUnjS1lK"},"source":["inplace addition"]},{"cell_type":"code","metadata":{"id":"TBuUEX71Rxou"},"source":["print(y)\n","y.add_(x)\n","print(y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FZ4DlliNk-0_"},"source":["Learn about other operations https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#operationsm"]},{"cell_type":"markdown","metadata":{"id":"tJdssKMxlkwe"},"source":["### Numpy bridge"]},{"cell_type":"code","metadata":{"id":"88VK_9Jylkwe"},"source":["# create numpy array\n","a = np.array([[1,2], [3,4]])\n","# transform numpy array into torch.Tensor\n","b = torch.from_numpy(a)\n","# make operation on this Tensor (in this case transpose)\n","b = b.transpose(1,0)\n","# transform back to numpy\n","c = b.numpy()                \n","\n","print(f\"{type(a)} \\n {a} \\n\")\n","print(f\"{type(b)} \\n {b} \\n\")\n","print(f\"{type(c)} \\n {c} \\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gpp2zVsVk-0_"},"source":["#### <font color=\"red\">**[PROBLEM III]:** </font>"]},{"cell_type":"markdown","metadata":{"id":"b16o5QKFlkwi"},"source":["-----\n","<span style=\"color:red\"> Using these two random matrices: </span>"]},{"cell_type":"code","metadata":{"id":"TC2oFY8llkwj"},"source":["x = np.random.randn(3, 10)\n","y = np.random.randn(4, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_cE4jEhBlkwm"},"source":["<span style=\"color:red\"> Do the following: </span>\n","* <span style=\"color:red\">transform $\\mathbf{x}$ and $\\mathbf{y}$ to torch.Tensors</span>\n","* <span style=\"color:red\">perform matrix mutliplication $\\mathbf{r1} = \\mathbf{x} \\cdot \\mathbf{y^T} $</span>  \n","<span style=\"color:blue\"> look in for pytorch function http://pytorch.org/docs/master/torch.html#torch.mm </span>  or\n","<span style=\"color:blue\">  http://pytorch.org/docs/master/torch.html#torch.matmul </span>  \n","* <span style=\"color:red\">perform matrix element-wise mutliplication $\\mathbf{r2} = \\mathbf{r1} \\cdot \\mathbf{r1} $</span>  \n","<span style=\"color:blue\"> look in for pytorch function http://pytorch.org/docs/master/torch.html#torch.mul </span> \n","* <span style=\"color:red\">perform scalar addition and scalar multiplication $\\mathbf{r3} = 2 * \\mathbf{r2} + 3 $</span>  \n","* <span style=\"color:red\">transform the result back to numpy </span>\n","\n","-----"]},{"cell_type":"code","metadata":{"id":"aWDAtz54lkwn"},"source":["# YOUR CODE HERE (replace 'None')\n","r1 = None\n","r2 = None\n","r3 = None\n","print(r3.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U_VqL45Blkws"},"source":["### CUDA stuff"]},{"cell_type":"markdown","metadata":{"id":"pcPi-hOSlkwt"},"source":["let us run on CUDA! ... if CUDA is available"]},{"cell_type":"code","metadata":{"id":"BD0YYuiMOgkv"},"source":["torch.cuda.is_available()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EwUaC4nXlkwv"},"source":["x = torch.randn(3, 10)\n","if torch.cuda.is_available():\n","    device = \"cuda\"          # a CUDA device object\n","    y = torch.ones_like(x).to(device)  # directly create a tensor on GPU\n","    x = x.to(device)                   \n","    z = x + y\n","    print(z) # notice \"device='cuda:0'\" when we print this part\n","    print()\n","    print(z.to(\"cpu\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nHxHgvOfRFCA"},"source":["##  Autograd: automatic differentiation"]},{"cell_type":"markdown","metadata":{"id":"wux_2jqxRBs0"},"source":["relevant tutorial\n","https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py\n"]},{"cell_type":"markdown","metadata":{"id":"4FZyAlm2lkw0"},"source":["*torch.Tensor* is the central class of the package. If you set its attribute *.requires_grad* as True, it starts to track all operations on it. When you finish your computation you can call *.backward()* and have all the gradients computed automatically. The gradient for this tensor will be accumulated into .grad attribute. "]},{"cell_type":"markdown","metadata":{"id":"3XsvhS5-lkw1"},"source":["**use of autograd**\n","\n","Lets start with simple example.\n","Consider the following function:\n","$$f = (x + y) \\cdot z$$\n","\n","For concretness let's take $x=2$, $y=-7$, $z=3$. The 'forward' calculation is shown in <span style=\"color:green\"> green </span> on the image below.\n","\n","Automaic differentiation provides the elegant tool to calculate derivatives of $f$ with respect to all variables, by 'backward' path.\n","\n","$$f = (x + y) \\cdot z = u \\cdot z $$\n","\n","$$ \\frac{\\partial f}{\\partial u} = z $$\n","\n","$$ \\frac{\\partial f}{\\partial z} = u = -5 $$\n","\n","$$ \\frac{\\partial f}{\\partial x} = \\frac{\\partial f}{\\partial u} \\cdot \\frac{\\partial u}{\\partial x} = z = 3$$\n","\n","$$ \\frac{\\partial f}{\\partial y} = \\frac{\\partial f}{\\partial u} \\cdot \\frac{\\partial u}{\\partial y} = z = 3$$\n","\n","![comp_graph_1](https://raw.githubusercontent.com/lyubonko/ucu2021cv/master/assignments/fig/comp_graph_1.png)"]},{"cell_type":"code","metadata":{"id":"rWdfj0DYlkw2"},"source":["# Create tensors.\n","# ('requires_grad' is False by default)\n","x = torch.tensor([2.], requires_grad=True)\n","y = torch.tensor([-7.], requires_grad=True)\n","z = torch.tensor([3.], requires_grad=True)\n","\n","# Build a computational graph.\n","f = (x + y) * z   \n","\n","# Compute gradients.\n","f.backward()\n","\n","# Print out the gradients.\n","print(x.grad)    \n","print(y.grad)    \n","print(z.grad) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FJSxjwiAk-1D"},"source":["#### <font color=\"red\">**[PROBLEM IV]** </font>"]},{"cell_type":"markdown","metadata":{"id":"fO2yZn6flkw5"},"source":["\n"," Next we will consider the computational graph of the following function \n","\n","$$f = \\frac{1}{1 + exp^{-(w_0 \\cdot x_0 + w_1 \\cdot x_1 + b )}} = \\frac{1}{1 + exp^{-(\\mathbf{w} \\cdot \\mathbf{x} + b )}}$$\n","\n","\n","![comp_graph_2](https://raw.githubusercontent.com/lyubonko/ucu2021cv/master/assignments/fig/comp_graph_2.png)\n","\n"," We are interested in computing partial derivatives: \n","\n","$$ \\frac{\\partial f}{\\partial \\mathbf{w}}  $$ \n","\n","$$ \\frac{\\partial f}{\\partial b}  $$ \n","\n","$$ \\frac{\\partial f}{\\partial \\mathbf{x}}  $$ \n","\n","define $\\{x_0, x_1\\}$ and $\\{w_0, w_1\\}$ as vector variables $\\mathbf{x}$ and $\\mathbf{w}$\n","look in for pytorch exponent function http://pytorch.org/docs/master/torch.html#torch.exp \n","use matrix operations\n","\n","You should get the numbers the same as on the figure"]},{"cell_type":"code","metadata":{"id":"vDpuQUuOlkw6"},"source":["w = torch.tensor([3., 5.], requires_grad=True)\n","x = torch.tensor([-2., 1.], requires_grad=True)\n","b = torch.tensor([2.], requires_grad=True)\n","\n","#YOUR CODE HERE (replace 'None')\n","f = None \n","\n","# Compute gradients.\n","f.backward()\n","\n","# Print out the gradients.\n","print(w.grad)\n","print(x.grad)      \n","print(b.grad) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7QFqSPhqk-1E"},"source":[""],"execution_count":null,"outputs":[]}]}