{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"a2_simple_network.ipynb","provenance":[{"file_id":"https://github.com/lyubonko/ucu2020cv/blob/master/assignments/a2_simple_network.ipynb","timestamp":1637187574561}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MJc9nrDy_fdE"},"source":["# Simple networks"]},{"cell_type":"markdown","metadata":{"id":"U1t8P2WF_dAR"},"source":["### Useful Links:\n","\n","* pytorch official documentation\n","http://pytorch.org/docs/master/index.html\n","\n","* pytorch discussion\n","https://discuss.pytorch.org/\n","\n","* pytorch official tutorials\n","https://pytorch.org/tutorials/"]},{"cell_type":"markdown","metadata":{"id":"Z8MRDiGWUkCB"},"source":["## Preliminaries"]},{"cell_type":"code","metadata":{"id":"IfCU7c5KUkCG"},"source":["import numpy as np\n","import os\n","from PIL import Image\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pKJJpL4JUkCI"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1sqUeL6jUkCL"},"source":["# to make interactive plotting possible\n","%matplotlib inline\n","# for auto-reloading external modules\n","%load_ext autoreload\n","%autoreload 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2v18tmDUkCN"},"source":["# make plots a bit nicer\n","plt.matplotlib.rcParams.update({'font.size': 18, 'font.family': 'serif'})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZrKaje3eUkCQ"},"source":["# random seed settings\n","torch.manual_seed(42)\n","np.random.seed(42)\n","\n","# data type (useful to have in pytorch)\n","dtype_np = np.float64\n","dtype_torch = torch.FloatTensor"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E5VuxU78_NRB"},"source":["# print versions\n","from platform import python_version\n","print(f\"python version: {python_version()}\")\n","print(f\"torch version: {torch.__version__}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SOnnHO4_XN7n"},"source":["### Pathes"]},{"cell_type":"code","metadata":{"id":"IqTvcz1BSDJr"},"source":["# transfer data to colab\n","!wget https://raw.githubusercontent.com/lyubonko/ucu2021cv/master/assignments/data/toy_data/data_class_train.txt\n","!wget https://raw.githubusercontent.com/lyubonko/ucu2021cv/master/assignments/data/toy_data/data_class_test.txt\n","\n","# create local folder with data\n","path_folder = \"data\"\n","if not os.path.exists(path_folder):\n","  os.mkdir(path_folder)\n","\n","# data pathes\n","path_data_train = os.path.join(path_folder, \"data_class_train.txt\")\n","path_data_test = os.path.join(path_folder, \"data_class_test.txt\")\n","\n","# move files \n","os.replace(\"data_class_test.txt\", path_data_test)\n","os.replace(\"data_class_train.txt\", path_data_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g8wxAx0AUkCT"},"source":["### Data (playground)"]},{"cell_type":"code","metadata":{"id":"R-HfiJehacH0"},"source":["# we will work with one file (but we can do it with two files)\n","path_data = path_data_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w0z3rxUUUkCT"},"source":["# load data\n","data = np.loadtxt(path_data)\n","dataX = data[:,0:2]\n","dataY = data[:,2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzE1sHScUkCW"},"source":["n_samples = data.shape[0]\n","dim_in = 2 # two features\n","dim_out = 3 # three classes\n","\n","n_train = int(n_samples * 0.7)\n","n_test = n_samples - n_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VL-MOE60UkCZ"},"source":["# train-test partition\n","perm = np.random.permutation(n_samples)\n","train_indx = perm[:n_train]\n","test_indx = perm[n_train:]\n","\n","dataX_train, dataY_train = dataX[train_indx,:], dataY[train_indx]\n","dataX_test, dataY_test = dataX[test_indx,:], dataY[test_indx]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lyiIizM6UkCd"},"source":["# visualize data\n","plt.figure(figsize=(10,5))\n","plt.plot(dataX_train[dataY_train==0,0], dataX_train[dataY_train==0,1],'ob', label=\"class1\")\n","plt.plot(dataX_train[dataY_train==1,0], dataX_train[dataY_train==1,1],'og', label=\"class2\")\n","plt.plot(dataX_train[dataY_train==2,0], dataX_train[dataY_train==2,1],'or', label=\"class3\")\n","\n","plt.plot(dataX_test[:,0], dataX_test[:,1],'xk', label=\"test\")\n","\n","plt.xlabel('feature #1')\n","plt.ylabel('feature #2')\n","plt.legend()\n","plt.xlim(-9, 9)\n","plt.ylim(-5, 12);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"emywYf7kUkCi"},"source":["## Two-layer Network ('by hand')\n","\n","\n","$$x_{hidden} = RELU(x  \\cdot W_1 + b_1)$$\n","$$y_{pred} = x_{hidden} \\cdot W_2 + b_2$$"]},{"cell_type":"code","metadata":{"id":"kvqsZejNUkCj"},"source":["dim_hidden = 100 # hidden dimension"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ujFGnvmUkCl"},"source":["# input \n","x = torch.from_numpy(dataX_train).type(dtype_torch)\n","y = torch.from_numpy(dataY_train).type(torch.LongTensor)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c0FLztlqUkCo"},"source":["* Weights and biases"]},{"cell_type":"markdown","metadata":{"id":"pm0AbfS_UkCo"},"source":["### <font color=\"red\"> **[PROBLEM I]**: </font>   \n"," <font color=\"red\"> Fill the missing part (weights and biases for the output layer) </font>  "]},{"cell_type":"code","metadata":{"id":"P6EaCFsSUkCp"},"source":["# Randomly initialize weights\n","w1_value = np.random.randn(dim_in, dim_hidden)\n","w2_value = None # YOUR CODE HERE\n","\n","# Randomly initialize biases\n","b1_value = np.random.randn(dim_hidden)\n","b2_value = None # YOUR CODE HERE\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZDNbEJQJXmP8"},"source":["* tell pytorch that these variables will participate in backprop. requires_grad=False by default, more details: https://pytorch.org/docs/stable/notes/autograd.html"]},{"cell_type":"code","metadata":{"id":"4j7AOmZNUkCr"},"source":["w1 = torch.from_numpy(w1_value).type(dtype_torch).requires_grad_(True)\n","w2 = torch.from_numpy(w2_value).type(dtype_torch).requires_grad_(True)\n","b1 = torch.from_numpy(b1_value).type(dtype_torch).requires_grad_(True)\n","b2 = torch.from_numpy(b2_value).type(dtype_torch).requires_grad_(True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KB_MBRG-UkCu"},"source":["* Loss (we will use cross-entropy loss), see documentation for details http://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss"]},{"cell_type":"code","metadata":{"id":"NQw_LYFbUkCv"},"source":["criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cKSu08rFUkCx"},"source":["* learning parameters"]},{"cell_type":"code","metadata":{"id":"f5MTxAyPUkCy"},"source":["learning_rate = 1e-3\n","n_iteration = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PDYPUHoDUkC0"},"source":["### <font color=\"red\"> **[PROBLEM II]**: </font>   \n"," <font color=\"red\"> Fill the missing part (last operation in forward pass to calculate *y_pred*) </font>  "]},{"cell_type":"code","metadata":{"id":"kD980w_HUkC1"},"source":["logger = {}\n","logger['iteration'] = []\n","logger['loss_iteration'] = []\n","\n","for t in range(n_iteration):  \n"," \n","    # forward pass\n","    x_hidden = x.mm(w1) + b1\n","    x_hidden_act = x_hidden.clamp(min=0) # apply RELU\n","    y_pred = None # YOUR CODE HERE\n","    \n","    # compute loss\n","    loss = criterion(y_pred, y)\n","\n","    # backprop\n","    loss.backward()\n","\n","    # update weights using gradient descent  \n","    w1.data -= learning_rate * w1.grad\n","    w2.data -= learning_rate * w2.grad\n","    b1.data -= learning_rate * b1.grad\n","    b2.data -= learning_rate * b2.grad\n","\n","    # manually zero the gradients\n","    w1.grad.zero_()\n","    w2.grad.zero_()\n","    b1.grad.zero_()\n","    b2.grad.zero_()      \n","    \n","    # reporting & logging       \n","    if t % 100 == 0:\n","        print(t, loss.item())\n","        \n","    logger['iteration'] += [t]\n","    logger['loss_iteration'] += [loss.item()]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZRVfrCSjUkC6"},"source":[" <font color=\"green\"> After visualizing the loss (cell below) you should see something like this </font>\n","\n","![loss_toy.png](https://raw.githubusercontent.com/lyubonko/ucu2021cv/master/assignments/fig/loss_toy.png)"]},{"cell_type":"code","metadata":{"id":"2thNWH0QUkC7"},"source":["# visualize loss\n","plt.figure(figsize=(10,5))\n","plt.plot(logger['iteration'], logger['loss_iteration'],'ob', label=\"loss\")\n","\n","plt.xlabel('iteration')\n","plt.ylabel('loss');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PlnAncYjUkDC"},"source":["### <font color=\"red\"> **[PROBLEM III]**: </font>   \n","<font color=\"red\"> Implement the fuction which takes x and predicts its class </font>  "]},{"cell_type":"code","metadata":{"id":"rWXjnPprUkDC"},"source":["def predict(x, w1, b1, w2, b2, dtype_torch=torch.FloatTensor):\n","    \"\"\"\n","    Prediction based on two-layer model (by hand)\n","    \n","    Args:\n","        x (numpy.array): sample\n","        w1, b1, w2, b2 (torch.Tensor) : weights and biases \n","    Returns:\n","        scalar: predicted class\n","    \"\"\"\n","    t = torch.from_numpy(x).type(dtype_torch)\n","    forward_pass = None # YOUR CODE HERE\n","\n","    return np.argmax(forward_pass)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_45l9ft5UkDE"},"source":["<span style=\"color:green\"> by running the following command you should get number bigger than 8 </span>"]},{"cell_type":"code","metadata":{"id":"7dgMC_-XUkDF"},"source":["np.sum(np.equal([predict(x, w1, b1, w2, b2) for x in dataX_train[:10]], [0, 2, 0, 1, 0, 2, 0, 0, 1, 0]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H-va53cfUkDI"},"source":["* Calculate accuracy"]},{"cell_type":"code","metadata":{"id":"Mh19f7hxUkDJ"},"source":["def get_accuracy(y, y_pred):\n","    \"\"\"\n","    Calculate accuracy given y and y_predicted\n","    \n","    Args:\n","        y (numpy.array): ground truth\n","        y_pred (numpy.array): predictated values\n","         \n","    Returns:\n","        scalar: accuracy\n","    \"\"\"\n","    n_samples = y.shape[0]\n","    return np.sum(y == y_pred)/n_samples * 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nWOLHYHSUkDL"},"source":["y_train_predict = np.zeros(n_train)\n","for i in range(n_train):\n","    y_train_predict[i] = predict(dataX_train[i], w1, b1, w2, b2)\n","\n","print(\"Train accuracy: %f\" % get_accuracy(y_train_predict, dataY_train))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QXY0TXHoUkDO"},"source":["### <font color=\"red\"> **[PROBLEM IV]**: </font>   \n","<font color=\"red\"> Calculate accuracy on the test set </font>"]},{"cell_type":"code","metadata":{"id":"h_JSf4NcUkDP"},"source":["#YOUR CODE HERE\n","y_test_predict = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1fPujWJSUkDR"},"source":["* Visualize decision boundary"]},{"cell_type":"code","metadata":{"id":"qg0G8AhXUkDR"},"source":["Nspace = 100\n","x1space = np.linspace(-9, 9, Nspace)\n","x2space = np.linspace(-5, 12, Nspace)\n","X,Y = np.meshgrid(x1space, x2space)\n","\n","Z = np.zeros((Nspace,Nspace))\n","for i in range(Nspace):\n","    for j in range(Nspace):\n","        x1 = x1space[j]\n","        y1 = x2space[i]\n","        x = np.array([x1,y1])\n","        Z[i,j] = predict(x, w1, b1, w2, b2)\n","\n","plt.figure(figsize=(10,5))\n","plt.pcolor(X, Y, Z, vmin=abs(Z).min(), vmax=abs(Z).max())\n","\n","plt.xlabel('feature #1')\n","plt.ylabel('feature #2')\n","plt.xlim(-9, 9)\n","plt.ylim(-5, 12);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QgUtCc5dUkDV"},"source":["## Two-layer Network, again ...  (with nn package) \n","\n","$$x_{hidden} = RELU(x  \\cdot W_1 + b_1)$$\n","$$y_{pred} = x_{hidden} \\cdot W_2 + b_2$$"]},{"cell_type":"markdown","metadata":{"id":"a5dNWjSAUkDV"},"source":["After some hard work we will use torch with all its power and elegance.  "]},{"cell_type":"markdown","metadata":{"id":"AtPNVmOUUkDW"},"source":["* Model"]},{"cell_type":"code","metadata":{"id":"qgAnFXS2Zz_V"},"source":["class Net(nn.Module):\n","  \n","  def __init__(self, dim_in, dim_hidden, dim_out):\n","    super(Net, self).__init__()\n","    self.fc1 = nn.Linear(dim_in, dim_hidden)\n","    self.fc2 = nn.Linear(dim_hidden, dim_out)\n","    \n","  def forward(self, x):\n","    x = self.fc2(F.relu(self.fc1(x)))\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PW3AQyDnUkDa"},"source":["model = Net(dim_in, dim_hidden, dim_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AJY2KW22UkDc"},"source":["* Loss (we will use cross-entropy loss)"]},{"cell_type":"code","metadata":{"id":"O0JWFwx7UkDd"},"source":["criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6CAjIBGWUkDf"},"source":["# input \n","x = torch.from_numpy(dataX_train).type(dtype_torch)\n","y = torch.from_numpy(dataY_train).type(torch.LongTensor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZG-zxJaFUkDh"},"source":["learning_rate = 1e-2\n","n_iteration = 1000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yt1TewKOUkDk"},"source":["logger = {}\n","logger['iteration'] = []\n","logger['loss_iteration'] = []\n","\n","for t in range(n_iteration):  \n","    \n","    # forward pass\n","    y_pred = model(x)\n","    \n","    # compute loss\n","    loss = criterion(y_pred, y)\n","\n","    # backprop\n","    loss.backward()\n","\n","    # update weights using gradient descent  \n","    for param in model.parameters():\n","        param.data -= learning_rate * param.grad.data \n","    \n","    # manually zero the gradients\n","    model.zero_grad()  \n","    \n","    # reporting & logging       \n","    if t % 100 == 0:\n","        print(t, loss.item())\n","        \n","    logger['iteration'] += [t]\n","    logger['loss_iteration'] += [loss.item()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AE7MW8OoUkDq"},"source":["def predict(x, model):\n","    \"\"\"\n","    Prediction based on two-layer model\n","    \n","    Args:\n","        x (numpy.array): feature vector of a sample\n","         \n","    Returns:\n","        scalar: predicted class for this sample\n","    \"\"\"    \n","    t = torch.from_numpy(x).type(dtype_torch)\n","    forward_pass = model(t)\n","    return np.argmax(forward_pass.data.numpy(), axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YvjiWaxTUkDs"},"source":["y_train_predict = predict(dataX_train,model)\n","print(\"Train accuracy: %f\" % get_accuracy(y_train_predict, dataY_train))\n","\n","y_test_predict = predict(dataX_test, model)\n","print(\"Test accuracy: %f\" % get_accuracy(y_test_predict, dataY_test))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NNikUxVCeVmt"},"source":["### <font color=\"red\"> **[PROBLEM V]**: </font>   \n","<font color=\"red\"> Visualize loss </font>"]},{"cell_type":"code","metadata":{"id":"loaofwicUkDo"},"source":["# YOUR CODE HERE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fp97qvcZQhPG"},"source":[""],"execution_count":null,"outputs":[]}]}